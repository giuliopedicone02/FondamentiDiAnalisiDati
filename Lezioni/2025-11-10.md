# Lunedì 10 novembre 2025 - Regressione Lineare

Nella scorsa lezione abbiamo parlato di modelli predittivi, nel caso di apprendimento supervisionato, il training set è composto da coppie X e Y vogliamo trovare una funzione h definita in X a valori in qualche E tale che se io faccio una predizione vorrei che y stimato sia uguale o simile allo y reale.

Posso definire una funzione di Loss, nel caso di problemi lineari è spesso consigliabile utilizzare il Mean Square Error che prende come parametro lo y stimato e y reale. La nostra funzione h vuole minimizzare l'errore o il rischio empirico facendo una media delle Loss. 

In un problema di regressione ho in input valori continui ed in output avrò valori continui.

Abbiamo più casi, partiamo dal caso di regressione semplice:
- n = m = 1: Si parla di Regressione Semplice

## Dataset di esempio: MPG (Miglia Per Gallone)

Mette in relazione diverse variabili relative alle automobili, 398 osservazioni ed 8 variabili:

- displacement: Variabile continua ratio, superficie ricoperta in un certo numero di secondi
- cylinders: Variabile discreta ordinale ratio
- horsepower: potenza
- weight: peso
- acceleration: accelerazione
- model_year: anno di fabbricazione
- origin: indica se la macchina è americana, giapponese o altro (ha solo 3 valori)
- mpg: miglia per gallone

L'obiettivo è voler capire data una macchina con un certo numero di cilindri, un certo peso etc il valore mpg, questo è possibile farlo utilizzando la regressione lineare.

## Visualizziamo le relazioni

Prendiamo due variabili: horsepower ed mpg e visualizziamole tramite scatterplot sembra esserci una relazione tra le due variabili, se ho una macchina con una potenza maggiore tendono ad essere meno efficienti. Se calcolassimo una covarianza, avremmo un trend discendente il segno della covarianza sarebbe negativa, ma il coefficiente di Pearson della covarianza misura solo relazioni di tipo **lineare**. Ma la relazione nel grafico non sembra lineare, ma somiglia molto di più ad una **parabola** o comunque una qualunque funzione quadratica. In ogni caso il modello lineare ci dà qualche informazione su questi dati.

## Il framework del modello di regressione

Voglio predire il valore di una variabile aleatoria Y a partire dal valore di una variabile aleatoria X passata come parametro di una funzione f deterministica sommata ad un valore epsilon che indica l'errore sistematico che cattura tutto ciò che f non riesce a spiegare. Epsilon sarà 0 solo quando sia X che Y sono perfettamente sovrapposte, hanno quindi gli stessi valori. 

In generale epsilon però è diverso da 0 per diversi motivi:
- Imperfezione del modello
- Variabili mancanti: difficle stimare il valore corretto di mpg solo con horsepower, dovremmo aggiungere altre informazioni o meglio altre variabili come il peso, i cilindri...
- Inerente stocasticità: Se introduco qualcosa di probabilistico abbiamo sempre un certo epsilon relativo all'incertezza

## Regressione Lineare Semplice

La formula della regressione lineare semplice è data da:

$$Y \approx \beta_0 + \beta_1X$$

nel nostro caso:

$$\text{mpg} \approx \beta_0 + \beta_1 \text{horsepower}$$

dove:

- X è la variabile indipendente, altri sinonimi sono: predittore, regressore, feature
- Y è la variabile dipendente, altri sinonimi sono: regressa, predetta
- $\beta_0, \beta_1$ sono detti coefficienti o parametri
- $\epsilon$ è il termine di errore, nel caso migliore piccolo e casuale

## Interpretazione Geometrica

I parametri $\beta_0, \beta_1$ non fa altro che muovere la retta nello spazio e cambiarne l'orientamento, in particolare se cambio $\beta_0$ la retta sale o scende rispetto all'asse delle y, se cambio $\beta_1$ la retta sarà shiftata a sinistra o destra sull'asse delle x

## Trovare la retta migliore

Il nostro obiettivo è quello di trovare la retta che passi per più punti possibili nel nostro scatterplot, per stabilire se una retta è migliore di un'altra posso utilizzare l'errore quadratico medio o MSE. Calcolo quindi la differenza tra:

$$
(f(x^{(i)}) - y^{(i)})^2
$$

Dal punto di vista geometrico vogliamo minimizzare la distanza tra tutti i punti e la retta

## Ordiary Least Squares (OLS)

Definisco 

$$\hat y_i = \hat \beta_0 + \hat \beta_1 x_i$$

e chiamo residuo le distanze date da:

$$e_i = y_i - \hat y_i$$

Definisco inoltre un valore chiamato Residual Sum of Squares come:

$$RSS = \sum_{i=1}^{n}(y_1 - \hat \beta_0 - \hat \beta_1 x_1)^2 $$

Somiglia molto all'MSE ma manca il fattore $\frac{1}{n}$, in questo caso non è necessario.

RSS è la funzione che noi vogliamo minimizzare.

Vogliamo trovare il punto di minimo impostando le derivate parziali a zero:

$$(\hat \beta_0, \hat \beta_1) = \arg \min_{\beta_0, \beta_1} RSS(\beta_0, \beta_1)$$

$$\frac{\partial RSS(\beta_0, \beta_1)}{\partial \beta_0} = 0$$
$$\frac{\partial RSS(\beta_0, \beta_1)}{\partial \beta_1} = 0$$

Costruisco quindi un sistema di equazioni che mi permettono di trovare i parametri $\beta_0$ e $\beta_1$ definite come segue:

$$\hat \beta_0 = \overline y - \hat \beta_1 \overline x$$

$$\hat \beta_1 = \frac{\sum_{i=1}^n(x_i - \overline x)(y_i - \overline y)}{\sum_{i=1}^n(x_i - \overline x)}$$

Quest'ultima formula non è altro che la covarianza, normalizzata per la varianza di x.

## Minimizzazione del rischio empirico

Se io utilizzo come funzione di perdita i residui al quadrato, posso definire come rischio empirico 

$$
\frac{1}{n}RSS
$$

## Interpretazione dei coefficienti di Regressione Lineare

Supponiamo di aver trovato nel dataset MPG i seguenti parametri:

$$y = 39.94 - 0.15 x$$

Possiamo capire che l'MPG per x=0, l'MPG è 39.94, lo slope ci permette di capire come si orienta la mia retta ma risponde anche alla domanda: "Se io aumento l'horsepower di un'unità mi devo aspettare un decremento di 0.15 MPG".

Se volessimo calcolare $f(x+1)$

$$f(x+1)-f(x)=\beta_0+\beta_1 (x+1)-\beta_0-\beta_1 x=\beta_1 (x+1-x)=\beta_1$$

Ma questo è possibile solo perchè il modello è semplice, in un contesto blackbox una cosa del geenre non sarebbe fattibile. 

Quindi $\beta_0$ è il valore di Y che otteniamo quando x è 0 e diminuisce di $\beta_1 = -0.15$ per ogni unità di incremento di horsepower. Attenzione a non dire che un incremento di un unità **causa**
un decrementi di -0.15 MPG **NON RAPPRESENTA UN RAPPORTO DI CAUSA-EFFETTO** è solo un qualcosa che ci aspettiamo di vedere, stiamo stimando infatti solo per un parametro (horsepower) discriminando cilindri, peso....

Le formule viste prima possiamo considerarli come **stimatori**, parliamo sempre di variabili aleatorie e sugli stimatori posso andare a misurare la distribuzione e stimare l'errore standard (SE) e degli intervalli di confidenza. Utile perchè mi permette di capire quanto è accurata la mia stima, quanto il mio modello in generale è accurato.

Ipotizziamo:

$$Y=2x+1$$

ci aspettiamo: $\hat \beta_0 \approx 1$ e $\hat \beta_1 \approx 2$.

Nel primo caso stiamo sottostimando la retta, nel secondo caso stiamo sovrastimando la retta, etc... Abbiamo tante rette che più o meno sbagliano tutte ma se facessimo la media tra queste rette riusciamo ad avvicinarci alla retta blu. Dobbiamo fare la media dei coefficienti, la media di queste distribuzioni corrisponde alla media della popolazione. Nell'ultimo grafico si vede come la retta relativa alla popolazione e la retta relativa alla media delle distribuzioni sono particolarmente simili tra loro.

## Intervalli di confidenza e Standard Error dei coefficienti

Troviamo tramite Python una tabella con i nomi dei coefficienti, le stime dei coefficienti, lo Standard Error che è una stima della deviazione standard della popolazione che si calcola a partire dalla deviazione standard del campione, inoltre ci fornisce gli intervalli di confidenza con Confidence Level del 95%. Significa che 95 volte su 100 la statistica vera si trova in questo intervallo con un margine di errore del 5%. L'ombreggiatura presente nel grafico ci permette di capire quanto è impreciso il nostro modello, se l'ombreggiatura è stretta il modello è abbastanza preciso.

## Test Statisticamente Significativi

Ho bisogno di ipotesi nulla ed ipotesi alternativa, una distribuzione, il p-value e si assume una decisione. Sempre tramite Python è possibile ottenere tabelle con:

- Nome del coefficiente
- Stima del valore del coefficiente
- Statisitca t della t di Student
- p-value
- Intervalli di confidenza al 95%

L'ipotesi nulla del test statistico è che il coefficiente $\beta_1=0$, se $\beta_1=0$ ho decorrelazione massima e non esiste alcuna relazione tra le due variabili, se ho un p-value piccolo sono sicuro che ho un valore di $\beta_1$ diverso da 0 e posso quindi rigettare l'ipotesi nulla. Non è un grosso problema trovare un p-value alto in $\beta_0$, se trovassimo un p-value alto in $\beta_1$ sarebbe un problema vuol dire che le due variabili sono decorrelate.

## Come misurare l'accuratezza del modello

Abbiamo due modi:

- Utilizziamo misure di Goodness-Of-Fit che vengono dalla statistica
- Utilizziamo misure di accuratezza predittiva che vengono dal machine learning

## Key Performance Metrics

Il Residual Standard Error stima la deviazione standard misurando la tipica predizione dell'errore in unità di Y, viene calcolato come:

$$RSE = \sqrt{\frac{RSS}{n-2}} $$

divido per n-2 per avere una misura unbiased o non distorta, ci fornisce una stima dello standard deviation, indica quindi quanto l'errore è grande. Rappresenta una misura assoluta di "lack of it" più piccolo è meglio è, si misura con la stessa unità di misura di Y. Non mi dice però in termini percentuali quanto è buono il nostro modello, per fare questo esiste la statistica $R^2$.

Prima di fare questo chiediamoci, quando il nostro modello è pessimo? Un esempio di un pessimo regressore è $Y=k$.

La statistica $R^2$ calcola un nuovo valore chiamato TSS Total Sum Square che è il migliore tra tutti i modelli sbagliati:

$$TSS = \sum_{i=1}^n(y_i-\overline y)^2$$

Calcolo la statistica come:

$$R^2 = 1 - \frac{RSS}{TSS}$$

L'RSS al massimo può essere uguale al TSS, ha range [0,TSS], in quanto il TSS è il modello peggiore che possiamo ottenere, se ho un fit perfetto l'RSS è 0, se RSS e TSS sono uguali il mio rapporto sarà 1.

Se il mio valore di $R^2$ è 0 il mio modello è pessimo, se mi avvicino ad 1 il mio modello è molto preciso. Un RSS pari a 0.7 indica che sto spiegando bene solo il 70% della varianza dei miei dati il restante 30% è il mio termine di errore epsilon.

Si nota inoltre che $R^2 = \rho^2$ dove $\rho$ è il coefficiente di correlazione di Pearson.

Non mi dice nulla sull'orientamento della retta ma solo quanto i punti sono vicini alla retta, non ha unità di misura, più alto è il valore di $R^2$ meglio è.

## Strumenti diagnostici grafici 

Possiamo capire anche graficamente se il nostro regressore è buono oppure no, se il mio modello è buono epsilon è piccolo e random.

Generalmente si plottano i residui rispetto ai valori fittati, il primo grafico è una situazione ottimale, il secondo grafico invece è ciò che non vogliamo ottenere la forma ad U indica che abbiamo un buon fit solo in pochi punti, l'errore è alto. Altro fenomeno è quello dell'allargamento, inizialmente l'errore è basso e va man mano crescendo. Sono grafici utili per confrontare modelli.

## Q-Q Plot

Vogliamo capire se i nostri residui si distribuiscono in maniera Gaussiana, spero di trovare il primo grafico ma spesso si trova il secondo caso.

## Regressore Lineaere Multiplo

Generalizzazione della regressione lineare semplice, sempre di tipo lineare ma con 2 o più variabili come ad esempio:

$$mpg = \beta_0 + \beta_1 horsepower + \beta_2 weight$$

Con due variabili la statistica $R^2$ sale da 61% a 71% con 3 variabili 81%, aggiungere variabili mi permette di avere una predizione sempre più accurata.

In generale: $$Y = \beta_0 + \beta_1 X_1 + \ldots + \beta_n X_n$$

## Interpretazione statistica

L'interpretazione geometrics non ci interessa, è più interessante quella statistica.

Iniziamo vedendo un regressore a due variabili 

$$mpg = \beta_0 + \beta_1 horsepower + \beta_2 weight$$

ed otteniamo i seguenti valori:

- $\beta_0 = 45.64$ Intercetta
- $\beta_1 = -0.05$ Effetto di Horsepower
- $\beta_2 = -0.01$ Effetto del peso

I parametri sono cambiati, quello che prima $\beta_1$ mi doveva predire da solo, ora l'effort è condiviso tra $\beta_1$ e $\beta_2$.

- $\beta_0$ rappresenta il valore di Y quando tutte le variabili indipendenti sono a 0
- $\beta_i$ indica l'incremento di y che ci aspettiamo di osservare quando $x_i$ si incrementa di una unità assumendo che tutte le altre variabili sono costanti.

Questo approccio ci permette di controllare per una variabile, posso fare delle assunzioni a pairità di quella variabile, questa tecnica è spesso utile per analisi dei dati su dati medici ad esempio voglio capire se il mio farmaco migliora l'ipertensione, lo somministro a pazienti giovani ed anziani e mi aspetto risultati differenti per le due categorie, se non metto l'età nel regressore i risultati non sono buoni perchè magari funziona meglio sugli anziani che sui giovani. Con l'età ho maggiore granularità sulle informazioni.

## Come stimare i coefficienti del regressore multiplo

Abbiamo il regressore:

$$y=\beta_0 + \beta_1 x_1 + \ldots + \beta_i x_i + \ldots + \beta_n x_n$$

Vogliamo minimizzare l'RSS:

$$RSS(\beta_0,\ldots,\beta_n) = \sum_{i=1}^m (y_i - \beta_0+\beta_1x_1^{(i)} + \ldots + \beta_n x_n^{(i)})^2$$

Cerchiamo quei valori che mi rendono la derivata nulla, utilizzo l'ottimizzazione convessa. Prendo tutte le derivate parziali faccio un sistema di equazioni e le risolvo per ottenere i vari parametri.

Trovo una forma vettoriale del tipo: $$\mathbf{y} = \mathbf{X} \mathbf{\beta} + \mathbf{e}$$

Prendiamo le nostre y e le metto in un vettore colonna di dimensione (m x 1) e faccio la stessa cosa per $\beta$ con dimensione ((n + 1) x 1)

$$\mathbf{y} = \begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
\vdots \\
y^{(m)}
\end{bmatrix},
\mathbf{X}=
\begin{bmatrix}
1 & x_1^{(1)} & x_2^{(1)} & \ldots & x_n^{(1)} \\
1 & x_1^{(2)} & x_2^{(2)} & \ldots &  x_n^{(2)} \\
\vdots & \vdots & \vdots \\
1 & x_1^{(m)} & x_2^{(m)} & \ldots &  x_n^{(m)} \\
\end{bmatrix},
\mathbf{\beta} = \begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\vdots \\
\beta_{n}
\end{bmatrix},
\mathbf{e} = \begin{bmatrix}
e^{(1)} \\
e^{(2)} \\
\vdots \\
e^{(m)}
\end{bmatrix}
$$

Vogliamo minimizzare: 

$$RSS(\mathbf{\beta}) = \sum_{i=1}^m (e^{(i)})^2 = \mathbf{e}^T \mathbf{e}$$

Possiamo farlo tramite:

$$\mathbf{\hat \beta} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

> Nota: Se ho indici di correlazioni molto alti tra due variabili, conviene sceglierne una sola delle due, avremmo due colonne con multipla linearità

## Il test F

Quando ho una regressione multipla, che può essere fatto anche su quella semplice ma è troppo complicato che si chiama F-Test.

Il regressore multiplo ha un valore se almeno uno dei coefficienti è diverso da 0. L'ipotesi nulla è che tutti i coefficienti siano uguali a 0, l'ipotesi alternativa è che almeno uno dei coefficienti sia diverso da 0.

Se la F-Statistic è uguale a 0 vuol dire che tutti i parametri sono a 0, è una procedura equivalente a controllare tutti i p-value e verificare se qualche valore è diverso da 0 o meno.

## Backward Elimination

Tecnica che ci permette di avere un regressore lineare con tutti i p-value buoni.

Supponiamo di inserire tutte le variabili nel mio regressore, non è un buona idea se abbiamo variabili strettamente correlate, ci accorgiamo che abbiamo variabili con un p-value alto come horsepower, cylinders, acceleration. Weight ha un p-value di 0 ma questo è vero se considero tutte le altri variabili costanti, se tolgo horsepower questo valore potrebbe cambiare. Questo regressore rischia essere fuorviante, dato che horsepower e cylinders sono correlate tra loro scegliamo di toglierne una delle due.

La tecnica di backward elimination ci dice di prendere la variavbile con p-value più alto e la togliamo, togliendo una variabile il p-value di horsepower è tornato sotto soglia ma cylinders ha un p-value sopra la soglia, tolgo anche quella ed ottengo quindi un regressore con tutti i p-value sotto la soglia.

## Correggere R-quadro

Una tecnica empirica è quella di utilizzare un valore:

$$\overline R^2 = 1- \frac{m-1}{m-n-1} (1-R)^2$$

dove m è il numero di data points e n è il numero di variabili indipendenti.

Generalmente quando facciamo regressione multipla si guarda questo, se questo valore scende il vantaggio di aver aggiunto una variabile non giustifica l'avere un modello più complesso.

## Predittori Qualitativi

Può succedere che all'interno di un nostro dataset ci siano variabili qualitative come Origin, come faccio ad inserirle come variabili indipendenti? Non abbiamo un ordinamento quindi è sbagliato mapparle in valori numerici, in questi casi si fa un espansione di queste features con delle dummy variables.

Scelgo due livelli su 3 perchè se aggiungessi la terza colonna ottengo una variabile fortemente correlata dalle prime due colonne in quanto è possibile calcolarla sapendo il valore delle prime due colonne.
