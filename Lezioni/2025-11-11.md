# Martedì 11 novembre 2025 - Beyond Linear Regression

Vedremo come estendere un modello lineare, parlando di regressione quadratica e polinomiale e come arriviamo quindi al machine learning, parleremo inoltre di overfitting come risolverlo tramite tecniche di regolarizzazione e successiva implementazione pratica.

## Problemi dei modelli lineari semplici

Hanno due principali problematiche:
- Deviazioni del mio modello dei dati: Quando guardo i residui ovvero come il modello devia tra i dati posso osservare una forma ad U, gli errori non sono uguai su tutto l'asse y, generalmente avviene quando abbiamo qualcosa di non lineare
- Multipla linearità: Dalla matrice di correlazione notiamo blocchi di variabili che sono molte correlate tra loro e che si influenzano a vicenda

## Termini di interazione

Modifica al modello lineare che introduce una deviazione dal modello lineare, non studiamo più una retta ma manteniamo una certa interpretabilità. Il modello additivo ci dice che il contributo di una variabile si somma al contributo di altre variabile. Assumiamo però che il contributo di una variabile sia indipendente dal contributo delle altre variabili. Ci aspettiamo che il mio modello non sia perfettamente additivo.

Costruiamo quindi un modello di interazione al quale aggiugniamo un terzo termine dove moltiplico le variabili tra loro ed aggiungo un nuovo coefficiente che cerca di cattirare come queste variabili si influenzano tra di loro.

$$
mpg = \beta_0 + \beta_1 h + \beta_2 w + \beta_3 w h
$$

Riscrivo raccogliendo per horsepower:

$$
mpg = \beta_0 + (\beta_1 + \beta_3 x weight) x horsepower + \beta_2 weight
$$

In pratica man mano che mi muovo sull'asse di weight trovo diverse rette con inclinazioni diverse, non ho più un modello lineare con il vantaggio di essere interpretabile.

Nel primo modello l'intercetta ha valore 39.93 che è il valore di mpg se tutte le variabili sono a zero, $\beta_1$ rappresenta il cambiamento che in media mi aspetto incrementando di una unità horsepower se weight è costante

Nel secondo modello l'intercetta la interpreto sempre alla stessa maniera, ha un valore differente 63.55 perchè sto cercando tutti i casi in cui sia horsepower che weight sono contemporanemanete a 0, horsepower è l'incremento medio che mi aspetto di vedere in mpg a parità di weight, weight mi indica l'incremento ched mi aspetto di osservare in mpg se aumento il peso di una unità e lascio horsepower costante, il terzo coefficiente che è il prodotto è un numero molto piccolo, quasi zero ma non è zero e ce lo dice il p-value che è inferiore a 0.05 e gli intervalli al 95% ci docono che il minimo che ci possiamo aspettare è 4.05e-05 ed il massimo 6.66e-05. Posso rendere i miei coefficienti arbitrariamente piccoli cambiando l'unità di misura, non mi posso quindi affidare al valore assoluto posso farlo scivolare verso lo 0 se voglio ed il test statistico ne tiene conto. Il coefficiente è assoluto, t è relativo, il p-value è relativo.

## Confrontiamo il modello con un regressore lineare

Possiamo farlo tramite plot dei residui e Q-Q Plot, con il termine di iterazione sui residui è migliorata di poco ma in termini di interazione è un modello migliore, il mio R2 si abbasserà.

Ma come faccio ad ottimizzare un modello con termini di interazione? Se volessi minimizzare RSS rispetto al valore Beta che contiene tutte le variabili, horsepower e weight sono invece dei coefficienti ma devo calcolare horsepower * weight associato a $\beta_3$.

**Ma quindi è un modello lineare oppure no?** La risposta è dipende, se guardo le variabili Beta è lineare ma non lineare in x (dovuta al prodotto tra weight ed horsepower), quando la ottimizzo è un problema di ottimizzazione lineare quando la utilizzo il modello è non lineare.

## La realtà Non - Lineare

Ci viene da pensare che esiste un modello matematico dal punto di vista analitico migliore di quello visto finora, ci viene da pensare di utilizzare una funzione quadratica. Anche in questo caso abbiamo una funzione non lineare in x ma lineare in Beta, posso trovare i miei parametri Beta in maniera semplice essendo lineari, devo solo elevare una colonna al quadrato.

$$mpg = \beta_0 + \beta_1 horsepower + \beta_2 horsepower^2$$

Il coefficiente di $\beta_2$ è molto piccolo, vicono allo 0 ma non è 0, ce lo dice il p-value. Ma l'intercetta come la interpreto? Rappresenta il valore che ottengo quando horsepower è 0, ma gli altri coefficienti come li interpretiamo? Possiamo modificare horsepower ed aspettarci che il suo quadrato resti costante? NO! questo modello non è più interpretabile. Scegliamo quindi un modello più complesso, più preciso ma non interpretabile.

## Regressione Polinomiale: Maggiore flessibilità

Prendo il mio problema lineare di base e faccio una espansione polinomiale facendolo diventare un polinomio di grado d. Modello lineare in beta, facile da ottimizzare e altamente non lineare in x.

$$mpg = \beta_0 + \beta_1 horsepower + \beta_2 horsepower^2 + \beta_3 horsepower^3 + \beta_4 horsepower^4$$

La quadratica ha un polinomio di grado 2, questo ha grado 4 ed è molto più flessibile avendo più punti di flesso.

Si applica anche al caso di più variabili aggiungendo un termine di interazione tra le variabili:

$$y = \beta_0 + \beta_1x + \beta_2y + \beta_3x^2 + \beta_4y^2 + \beta_5 xy$$

## Trade-off di interpretabilità

Non sappiamo più rispondere alla domanda: Qual è l'effetto di horsepower su MPG? Ci spostiamo quindi ad un approccio machine learning

## Da capire a predire

Nell'approccio machine learning cerco di ottimizzare il modello su dati che non ha visto, uso metriche basate sul test set, abbraccio la complessità e ottimizzo su dati mai visti. La statistica in assenza di assunzioni forti diventa poco affidabile, fare test statistici su una retta è semplice farlo su un polinomio è impossibile farlo con la statistica.

## Metriche di predizione

Potrei continuare ad usare R-Quadro ma non è adatto. Utilizziamo 3 metriche:

- Mean Square Error: Media degli scarti quadratici ($\frac{1}{n}RSS$) l'unità di misura è la stessa ma al quadrato, stesso problema riscontrato con la varianza. Più basso è meglio è ma è difficle da interpretare.
- Root Mean Square Error: Radice quadrata dell'MSE ci riconduciamo ad una unità di misura che è òa stessa di quella di partenza
- Mean Absolute Error: Anche in questo caso manteniamo la stessa unità di misura di partenza, l'MSE penalizza maggiormente gli scarti più grossi mentre il valore assoluto penalizza in maniera lineare

L'RMSE è meno facile da intuire e meno interpetabile rispetto al MAE.

## Il pericolo dell'overfitting

Se il grado 2 è buono vuol dire che il grado 20 sia migliore? Avere un numero alto di parametri ci permette di ottenere un modello che passa per tutti i punti, ma a che costo?

Il modello lineare soffre di underfitting ma non segue il pattern ha un alto bias (errore sistematico alto) ed una bassa varianza. Il modello quadratico ha un buon bilanciamento di bias e varianza . Un alto numero di parametri porta ad overfitting, ha un bias basso ed una alta varianza significa alta instabilità se tolgo un dato il modello cambia drasticamente.

## Regolarizzazione

Tecnica che cerca di abbassare la varianza, alzando il bias ma voglio trovare una via di mezzo. In geenrale il modo in cui costruisco sistemi regolarizzati è sommando il costo iniziale RSS ad un termoine di penalità che regola il rapporto tra bias e varianza. Se aggiungo una penalità bassa avrò varianza alta e bias basso.

## Ridge Regression (L2)

Si costruisce aggiungendo come termine di penalità la somma dei quadrati dei coefficienti escluso l'intercetta ($\beta_0$). Viene detta regolarizzazione L2 perchè se ho un vettore Beta, la norma (il suo modulo) che indica la distanza del vettore dal centro, utilizzo un iperparametro Lambda, se Lambda è ugiale a zero ottengo il regressore non regolarizzato, con Lambda grande ottengo una regolarizzazione pesante. Lambda ha un range [0, inf], il valore dipende molto da y non esiste un valore consigliato.

La regolarizzazione cerca di dare meno peso a variabili correlate tra loro rispolvendo il problema della multipla linearità.

Quando si applica la regolarizzazione Ridge si fa SEMPRE una standardizzazione delle feature, se le feature hanno scale diverse queste feature tendono a richiedere coefficienti più o meno grandi. Ho dei problemi se vado a guardare i coefficienti quelli che ottengo con OLS e con Ridge sono molto differenti, tutte le considerazioni statistiche non le posso più vedere attendibili, possiamo solo affidarci al modulo di questo valore per fare feature selection e capire quale variabile eliminare in base al coefficiente in valore assoluto più piccolo. Nel nostro caso rimuovere acceleration porta ad una leggera sottostima ma rimuovere weight o model_year farebbe cambiare di molto il modello.

## Lasso Regression (L1)

La tecnica di regolarizzazione che ci permette di spendere delle variabili, ci permette di aggiungere una penalità di tipo L1, la norma del vettore è la somma dei valori assoluti delle componenti. Ci permette di fare feature selection. Anche in questo caso non posso interpretare i coefficienti, ma una volta fatta feature selection posso lavorare su meno parametri.

## Curva di validazione

Il grafico rappresenta diverse curve di validation per Ridge Regression con grado pari a 15, vado a misurare come cambia il valore di training. Per valori bassi di lambda ho valori di training che tendono a crescere aumentando lambda, aumenta il bias, ma a noi non importa cosa succede sul training importa cosa succede sul test set.

Sul test set aumentando lambda gli errori tendono a decrescere fino ad arrivare ad un punto di equilibrio.

